{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMosIWoiID5mNE6mHsAozkA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wndgua0468/machine_learning/blob/main/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B512%EC%A3%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbPTTBXE-iu7"
      },
      "outputs": [],
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this test with increasing difficulty from 1-5\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score much less\n",
        "# than your Category 5 question.\n",
        "# ======================================================================\n",
        "#\n",
        "# Computer Vision with CNNs\n",
        "#\n",
        "# This task requires you to create a classifier for horses or humans using\n",
        "# the provided dataset. \n",
        "#\n",
        "# Please make sure your final layer has 2 neurons, activated by softmax \n",
        "# as shown. Do not change the provided output layer, or tests may fail.\n",
        "#\n",
        "# IMPORTANT: Please note that the test uses images that are 300x300 with \n",
        "# 3 bytes color depth so be sure to design your input layer to accept\n",
        "# these, or the tests will fail.\n",
        "#\n",
        "\n",
        "# =========== 합격 기준 가이드라인 공유 ============= #\n",
        "# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n",
        "# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n",
        "# =================================================== #\n",
        "# 문제명: Category 3 - Horses Or Humans type A\n",
        "# val_loss: 0.028\n",
        "# val_acc: 0.98\n",
        "# =================================================== #\n",
        "# =================================================== #\n",
        "\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "dataset_name = 'horses_or_humans'\n",
        "#dataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True)\n",
        "\n",
        "train_dataset = tfds.load(name=dataset_name, split='train')\n",
        "valid_dataset = tfds.load(name=dataset_name, split='test')\n",
        "\n",
        "def preprocess(data):\n",
        "    # YOUR CODE HERE\n",
        "    x = data['image']\n",
        "    y = data['label']\n",
        "    # image 정규화(Normalization)\n",
        "    x = tf.cast(x, tf.float32) / 255.0\n",
        "    x = tf.image.resize(x, size=(300, 300))\n",
        "    return x, y\n",
        "##데이터 업로드\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as mping\n",
        "\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "url_train = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "url_test = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "\n",
        "urllib.request.urlretrieve(url_train, 'horse-or-human.zip')\n",
        "local_zip = 'horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/horse-or-human/')\n",
        "zip_ref.close()\n",
        "\n",
        "urllib.request.urlretrieve(url_test, 'validation-horse-or-human.zip')\n",
        "local_zip = 'validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/validation-horse-or-human/')\n",
        "\n",
        "\n",
        "##데이터전처리\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale=1/255.,\n",
        "                                   horizontal_flip = True,\n",
        "                                   rotation_range = 35,\n",
        "                                   zoom_range = 0.2)\n",
        "train_dir = '/content/horses_or_humans'\n",
        "valid_dir = ''\n",
        "trian_gen = image_generator.flow_from_directory(train_dir,\n",
        "                                              target_size = (300,300),\n",
        "                                              batch_size = 128,\n",
        "                                              class_mode = 'binary')\n",
        "valid_gen = image_generator.flow_from_directory(valid_dir,\n",
        "                                              target_size = (300,300),\n",
        "                                              batch_size = 128,\n",
        "                                              class_mode = 'binary')\n",
        "\n",
        "\n",
        "def solution_model():\n",
        "    train_data = train_dataset.map(preprocess).batch(32)\n",
        "    valid_data = valid_dataset.map(preprocess).batch(32)\n",
        "\n",
        "    tf.keras.Sequential([\n",
        "        ##convolution층\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=(300, 300, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding='same', input_shape=(300, 300, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding='same', input_shape=(300, 300, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "        ##출력층\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.laters.Dense(256, activation='relu'),\n",
        "        tf.keras.laters.Dropout(0,3),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  \n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(2, activation='softmax'),\n",
        "    ])\n",
        "    model.compile(optimizer= RMSprop(lr=0.001),\n",
        "                loss = 'binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    \n",
        "    checkpoint_path = \"my_checkpoint.ckpt\"\n",
        "    checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n",
        "                             save_weights_only=True, \n",
        "                             save_best_only=True, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=1)\n",
        "\t\t\t\t\t\t\t \n",
        "    model.fit(train_gen,validation_data=(valid_gen),epochs=10,callbacks=[checkpoint],)\n",
        "\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this\n",
        "# This .h5 will be uploaded to the testing infrastructure\n",
        "# and a score will be returned to you\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"TF3-horses-or-humans-type-A.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "url_train = \"https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\"\n",
        "url_test = \"https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\"\n",
        "\n",
        "urllib.request.urlretrieve(url_train, 'horse-or-human.zip')\n",
        "local_zip = 'horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/horse-or-human/')\n",
        "zip_ref.close()\n",
        "\n",
        "urllib.request.urlretrieve(url_test, 'validation-horse-or-human.zip')\n",
        "local_zip = 'validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/validation-horse-or-human/')\n"
      ],
      "metadata": {
        "id": "1Oe4fFgR-kB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "image_generator = ImageDataGenerator(rescale=1/255.,\n",
        "                                     horizontal_flip=True,\n",
        "                                     rotation_range=35,\n",
        "                                     zoom_range=0.2)\n",
        "train_dir = '/content/horse-or-human'\n",
        "train_gen = image_generator.flow_from_directory(train_dir,\n",
        "                                                target_size=(300, 300),\n",
        "                                                batch_size=128,\n",
        "                                                class_mode='binary')\n"
      ],
      "metadata": {
        "id": "48pYSEkA-lz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class_labels = ['horses', 'humans']\n",
        "batch = next(train_gen)\n",
        "image, labels = batch[0], batch[1]\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i in range(32):\n",
        "    ax = plt.subplot(4, 8, i+1)\n",
        "    plt.imshow(image[i])\n",
        "    plt.title(class_labels[int(labels[i])])\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dex5Qzor-nd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_generator = ImageDataGenerator(rescale=1/255.,\n",
        "                                   horizontal_flip = True,\n",
        "                                   rotation_range = 35,\n",
        "                                   zoom_range = 0.2)\n",
        "train_dir = '/content/horses_or_humans'\n",
        "trian_gen = image_generator.flow_from_directory(train_dir,\n",
        "                                              target_size = (300,300),\n",
        "                                              batch_size = 128,\n",
        "                                              class_mode = 'binary')"
      ],
      "metadata": {
        "id": "XMAbz7sL-pqy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}